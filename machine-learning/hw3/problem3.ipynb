{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f6f08d",
   "metadata": {},
   "source": [
    "### problem 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2806dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import DictReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "441dabf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "vocab_size = 0\n",
    "examples = []\n",
    "training_size = 0\n",
    "test_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1de600f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/28562/Desktop/reviews_tr.csv', 'r') as f:\n",
    "    reader = DictReader(f)\n",
    "    for row in reader:\n",
    "        training_size += 1\n",
    "        label = row['rating'] == '1'\n",
    "        words = row['text'].split(' ')\n",
    "        for word in words:\n",
    "            if word not in vocab:\n",
    "                vocab[word] = vocab_size\n",
    "                vocab_size += 1\n",
    "        examples.append((label, [vocab[word] for word in words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04fbf215",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/28562/Desktop/reviews_te.csv', 'r') as f:\n",
    "    reader = DictReader(f)\n",
    "    for row in reader:\n",
    "        test_size += 1\n",
    "        label = row['rating'] == '1'\n",
    "        words = row['text'].split(' ')\n",
    "        for word in words:\n",
    "            if word not in vocab:\n",
    "                vocab[word] = vocab_size\n",
    "                vocab_size += 1\n",
    "        examples.append((label, [vocab[word] for word in words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ec3a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = examples[:training_size]\n",
    "test_data = examples[training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e590005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros\n",
    "\n",
    "def bag_of_words_rep(word_ids, dim):\n",
    "    bow_vector = zeros(dim) # creates a numpy.ndarray of shape (dim,)\n",
    "    for word_id in word_ids:\n",
    "        bow_vector[word_id] += 1\n",
    "    return bow_vector\n",
    "\n",
    "first_bow_vector = bag_of_words_rep(examples[0][1], vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "036805e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def new_bag_of_words_rep(word_ids):\n",
    "    dic = defaultdict(int)\n",
    "    for word_id in word_ids:\n",
    "        dic[word_id] += 1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87a993b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(w, x):\n",
    "    ret = 0\n",
    "    for key in x.keys():\n",
    "        ret += w[key] * x[key]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58f5464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(w, x):\n",
    "    for key in x.keys():\n",
    "        w[key] += x[key]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7576bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(w, x):\n",
    "    for key in x.keys():\n",
    "        w[key] -= x[key]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b9fdecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of memory is estimated as 29997125000 bytes.\n"
     ]
    }
   ],
   "source": [
    "print(f'The amount of memory is estimated as {round(training_size * vocab_size / 8)} bytes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2520e8",
   "metadata": {},
   "source": [
    "### problem 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e8372ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def online_perceptron(training):\n",
    "    n = len(training)\n",
    "    d = vocab_size\n",
    "    w = zeros(d)\n",
    "    for i in range(n):\n",
    "        y_i = training[i][0]\n",
    "        x_i = new_bag_of_words_rep(training[i][1])   \n",
    "        if (y_i and dot(w, x_i) <= 0) or (not y_i and dot(w, x_i) > 0):\n",
    "            if y_i:\n",
    "                w = add(w, x_i)\n",
    "            else:\n",
    "                w = sub(w, x_i)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4509aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = online_perceptron(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb8b82dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(w, data):\n",
    "    n = len(data)\n",
    "    err = 0\n",
    "    for i in range(n):\n",
    "        y_i = data[i][0]\n",
    "        x_i = new_bag_of_words_rep(data[i][1])  \n",
    "        if (y_i and dot(w, x_i) <= 0) or (not y_i and dot(w, x_i) > 0):\n",
    "            err += 1\n",
    "    return err / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e93b1e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error rate is 0.133159\n",
      "test error rate is 0.13582946501646248\n"
     ]
    }
   ],
   "source": [
    "train_err_rate = error_rate(weight, training_data)\n",
    "test_err_rate = error_rate(weight, test_data)\n",
    "print(f'training error rate is {train_err_rate}')\n",
    "print(f'test error rate is {test_err_rate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cf0365",
   "metadata": {},
   "source": [
    "### problem 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f020afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class new_tuple(tuple):\n",
    "    def __lt__(self,other):\n",
    "        return self[1] > other[1]\n",
    "\n",
    "def top_ten(w, best=True):\n",
    "    temp = w\n",
    "    if not best:\n",
    "        temp = -temp\n",
    "    wid = list(enumerate(temp))\n",
    "    heap = []\n",
    "    #override the existing \"cmp_lt\" module function with your function\n",
    "    for pair in wid:\n",
    "        heapq.heappush(heap, new_tuple(pair))\n",
    "    ret = []\n",
    "    for i in range(10):\n",
    "        tu = heapq.heappop(heap)\n",
    "        ret.append(list(vocab.keys())[tu[0]])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39e63869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest weights: ['perfection', 'gem', 'incredible', 'heaven', 'superb', 'phenomenal', 'amazing', 'worried', 'heavenly', 'perfect']\n",
      "lowest weights: ['mediocre', 'worst', 'meh', 'disappointing', 'lacked', 'underwhelmed', 'flavorless', 'bland', 'poisoning', 'disgusting']\n"
     ]
    }
   ],
   "source": [
    "print(f'highest weights: {top_ten(weight)}')\n",
    "print(f'lowest weights: {top_ten(weight, best=False)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509223f",
   "metadata": {},
   "source": [
    "### problem 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "284d420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_online_perceptron(training):\n",
    "    n = len(training)\n",
    "    d = vocab_size\n",
    "    w = zeros(d)\n",
    "    avg_w = zeros(d)\n",
    "    for i in range(n):\n",
    "        y_i = training[i][0]\n",
    "        x_i = new_bag_of_words_rep(training[i][1])   \n",
    "        if (y_i and dot(w, x_i) <= 0) or (not y_i and dot(w, x_i) > 0):\n",
    "            if y_i:\n",
    "                w = add(w, x_i)\n",
    "            else:\n",
    "                w = sub(w, x_i)\n",
    "        avg_w = avg_w + w\n",
    "    return avg_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5dfa067",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_weight = avg_online_perceptron(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e768fe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error rate is 0.104548\n",
      "test error rate is 0.10685613609811259\n"
     ]
    }
   ],
   "source": [
    "train_err_rate = error_rate(avg_weight, training_data)\n",
    "test_err_rate = error_rate(avg_weight, test_data)\n",
    "print(f'training error rate is {train_err_rate}')\n",
    "print(f'test error rate is {test_err_rate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb7c2b",
   "metadata": {},
   "source": [
    "### problem 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a82bf58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest weights: ['perfection', 'perfect', 'incredible', 'perfectly', 'gem', 'fantastic', 'delicious', 'amazing', 'excellent', 'disappoint']\n",
      "lowest weights: ['worst', 'mediocre', 'bland', 'meh', 'disappointing', 'awful', 'horrible', 'terrible', 'lacked', 'flavorless']\n"
     ]
    }
   ],
   "source": [
    "print(f'highest weights: {top_ten(avg_weight)}')\n",
    "print(f'lowest weights: {top_ten(avg_weight, best=False)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9859aa8",
   "metadata": {},
   "source": [
    "### problem 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7db3e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_mulpass_online_perceptron(training):\n",
    "    n = len(training)\n",
    "    d = vocab_size\n",
    "    w = zeros(d)\n",
    "    avg_w = zeros(d)\n",
    "    for i in range(n-1):\n",
    "        y_i = training[i][0]\n",
    "        x_i = new_bag_of_words_rep(training[i][1])   \n",
    "        if (y_i and dot(w, x_i) <= 0) or (not y_i and dot(w, x_i) > 0):\n",
    "            if y_i:\n",
    "                w = add(w, x_i)\n",
    "            else:\n",
    "                w = sub(w, x_i)\n",
    "                \n",
    "        y_i2 = training[i+1][0]\n",
    "        x_i2 = new_bag_of_words_rep(training[i+1][1])   \n",
    "        if (y_i2 and dot(w, x_i2) <= 0) or (not y_i2 and dot(w, x_i2) > 0):\n",
    "            if y_i2:\n",
    "                w = add(w, x_i2)\n",
    "            else:\n",
    "                w = sub(w, x_i2)\n",
    "        avg_w = avg_w + w\n",
    "    return avg_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e41df73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mulpass_weight = avg_mulpass_online_perceptron(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbfff738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error rate is 0.103399\n",
      "test error rate is 0.10578154578566921\n"
     ]
    }
   ],
   "source": [
    "train_err_rate = error_rate(avg_mulpass_weight, training_data)\n",
    "test_err_rate = error_rate(avg_mulpass_weight, test_data)\n",
    "print(f'training error rate is {train_err_rate}')\n",
    "print(f'test error rate is {test_err_rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3c4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
